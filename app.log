DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\docstore.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/docstore.json
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\index_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/index_store.json
DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./store\graph_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/graph_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\default__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/default__vector_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\image__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/image__vector_store.json
INFO:llama_index.indices.loading:Loading all indices.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openaipublic.blob.core.windows.net:443
DEBUG:urllib3.connectionpool:https://openaipublic.blob.core.windows.net:443 "GET /encodings/cl100k_base.tiktoken HTTP/1.1" 200 1681126
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\docstore.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/docstore.json
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\index_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/index_store.json
DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./store\graph_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/graph_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\default__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/default__vector_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\image__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/image__vector_store.json
INFO:llama_index.indices.loading:Loading all indices.
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.128.25:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\docstore.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/docstore.json
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\index_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/index_store.json
DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./store\graph_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/graph_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\default__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/default__vector_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\image__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/image__vector_store.json
INFO:llama_index.indices.loading:Loading all indices.
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 187-745-609
INFO:werkzeug:127.0.0.1 - - [01/Mar/2024 14:38:04] "GET / HTTP/1.1" 200 -
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\docstore.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/docstore.json
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\index_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/index_store.json
DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./store\graph_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/graph_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\default__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/default__vector_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\image__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/image__vector_store.json
INFO:llama_index.indices.loading:Loading all indices.
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): openaipublic.blob.core.windows.net:443
DEBUG:urllib3.connectionpool:https://openaipublic.blob.core.windows.net:443 "GET /encodings/cl100k_base.tiktoken HTTP/1.1" 200 1681126
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.217:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\docstore.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/docstore.json
DEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from ./store\index_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/index_store.json
DEBUG:llama_index.graph_stores.simple:Loading llama_index.graph_stores.simple from ./store\graph_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/graph_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\default__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/default__vector_store.json
DEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from ./store\image__vector_store.json.
DEBUG:fsspec.local:open file: C:/Users/emmau/Downloads/chatbot/store/image__vector_store.json
INFO:llama_index.indices.loading:Loading all indices.
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 536-107-125
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 13:58:48] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 13:58:48] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:00:03] "GET / HTTP/1.1" 200 -
DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False
DEBUG:httpx:load_verify_locations cafile='C:\\Users\\emmau\\Downloads\\chatbot\\chatbot\\lib\\site-packages\\certifi\\cacert.pem'
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001C297161240>, 'json_data': {'input': ['Hi'], 'model': <OpenAIEmbeddingModeModel.TEXT_EMBED_ADA_002: 'text-embedding-ada-002'>, 'encoding_format': 'base64'}}
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C297196050>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C297117540> server_hostname='api.openai.com' timeout=60.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C297196020>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Mar 2024 13:00:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-ktegm0hmqbjm1lzjvz4nouvd'), (b'openai-processing-ms', b'17'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-request-id', b'req_13da564bbfb3d6c1e5b454a3ca3d78b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XlxFg1bieyTqla2Cd6G.DhkIf9TQulc3Y2Hb4nJGOXQ-1709470809-1.0.1.1-O_XBUdiyC0_EP4rk6nqXbpNNYGq5oxMNJJe_eTI9UbsZ_jU__6xeuUVaH13HCWAyWN065C7AFaG6bdBFs.Rpig; path=/; expires=Sun, 03-Mar-24 13:30:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=r.fPggcIDeEZ0.1bBsHLpUjoh2xOY.0lSUATtjuoTQk-1709470809756-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e9cece5e82d7a1-LOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/embeddings "200 OK"
DEBUG:llama_index.indices.utils:> Top 2 nodes:
> [Node 6cae622d-b6fd-45e3-8861-2f835462ae03] [Similarity score:             0.747289] 9
> [Node 3abbdf58-b6f5-4ab4-ba53-7b2f86be1ba2] [Similarity score:             0.746851] 10
DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False
DEBUG:httpx:load_verify_locations cafile='C:\\Users\\emmau\\Downloads\\chatbot\\chatbot\\lib\\site-packages\\certifi\\cacert.pem'
DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are a chatbot, able to have normal interactions, as well as talk about data related to Nigeria. If you are asked anything out of context, just say you don't knowyou were trained on different data from the NBS\nContext information is below.\n--------------------\npage_label: Page 9\nfile_path: data\\LPG_DECEMBER_2023_REPORT.pdf\n\n9\n\npage_label: Page 10\nfile_path: data\\LPG_DECEMBER_2023_REPORT.pdf\n\n10\n--------------------\n"}, {'role': 'user', 'content': 'Hi'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}
DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None
DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2972094B0>
DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C28EE231C0> server_hostname='api.openai.com' timeout=60.0
DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C297209480>
DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_headers.complete
DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:send_request_body.complete
DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Mar 2024 13:00:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-ktegm0hmqbjm1lzjvz4nouvd'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39876'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'186ms'), (b'x-request-id', b'req_4e76d3f04e3ab5dc0a3b1ffafcec4541'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X9bysIZdqOHDQHP5S6gcibo6svPEGyttwH1p2zME7o4-1709470810-1.0.1.1-uEx24UBp4DduVbxepnsfTc_VOUCVbJd9ogS12h1lX2SdUCuYIp1lMYZrmFIGCQWnSWIi4feq1lymmgKzLbyOaQ; path=/; expires=Sun, 03-Mar-24 13:30:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n4kvYvmnPLHyQFMn9EgWe.SodSFeQi4uxUKvENOg1Jo-1709470810835-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e9ced26c42d799-LOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>
DEBUG:httpcore.http11:receive_response_body.complete
DEBUG:httpcore.http11:response_closed.started
DEBUG:httpcore.http11:response_closed.complete
DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
INFO:root:User question: Hi
INFO:root:AI response: Hello! How can I assist you today?
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:00:10] "POST /chat HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:01:58] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:02:16] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:02:50] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:03:14] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:03:18] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:04:53] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:05:00] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:05:17] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:05:50] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:06:37] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:07:18] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:07:47] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:07:48] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:07:49] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:01] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:03] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:24] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:26] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:26] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:14:57] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:15:28] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:16:05] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:16:07] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:17:08] "GET / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [03/Mar/2024 14:17:23] "GET / HTTP/1.1" 200 -
